{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notes_pannes.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Utilisation d'un Modèle Pré-Entrraîné\n",
    "#Le fine-tuning consiste à prendre un modèle de langage pré-entraîné sur un vaste corpus de données générales et à l'ajuster \n",
    "# (fine-tuner) sur un ensemble de données spécifique à votre tâche. Pour la classification de texte, vous pouvez utiliser \n",
    "# des modèles comme BERT, DistilBERT, ou RoBERTa.\n",
    "\n",
    "#2. Avantages du Fine-Tuning\n",
    "#Connaissances Générales : Le modèle pré-entraîné a déjà appris une grande quantité de connaissances générales sur le langage, \n",
    "# ce qui lui permet de mieux comprendre les nuances du texte.\n",
    "#Adaptation Spécifique : En fine-tunant le modèle sur vos données spécifiques, vous pouvez l'adapter pour qu'il fasse des \n",
    "# prédictions précises pour votre tâche particulière.\n",
    "\n",
    "data = {\n",
    "    \"note\": [\n",
    "        \"Le serveur est en panne, tout est bloqué.\",\n",
    "        \"L'application est lente à charger.\",\n",
    "        \"Une fonctionnalité mineure ne fonctionne pas.\",\n",
    "        \"La base de données est corrompue.\",\n",
    "        \"La page de connexion prend du temps à s'afficher.\",\n",
    "        \"Le bouton de téléchargement ne fonctionne pas.\",\n",
    "        \"Le réseau est complètement hors service.\",\n",
    "        \"Il y a un léger décalage dans l'affichage.\",\n",
    "        \"Le système redémarre de manière aléatoire.\",\n",
    "        \"Certains utilisateurs ne peuvent pas se connecter.\",\n",
    "        \"Les emails ne sont pas envoyés correctement.\",\n",
    "        \"Le site web est inaccessible pour certains utilisateurs.\",\n",
    "        \"Les notifications push ne fonctionnent pas.\",\n",
    "        \"Les rapports ne sont pas générés comme prévu.\",\n",
    "        \"Le paiement en ligne ne fonctionne pas.\",\n",
    "        \"Le temps de réponse du serveur est très lent.\",\n",
    "        \"Des erreurs 500 apparaissent fréquemment.\",\n",
    "        \"L'interface utilisateur est boguée.\",\n",
    "        \"Des fichiers sont manquants dans la base de données.\",\n",
    "        \"Les utilisateurs sont déconnectés automatiquement.\",\n",
    "        \"Le système de sauvegarde ne fonctionne pas.\",\n",
    "        \"Le processus de login est très lent.\",\n",
    "        \"Des erreurs de validation des données.\",\n",
    "        \"Les mises à jour ne sont pas appliquées correctement.\",\n",
    "        \"La recherche dans l'application ne fonctionne pas.\",\n",
    "        \"Le tableau de bord ne s'affiche pas.\",\n",
    "        \"Les utilisateurs ne reçoivent pas leurs confirmations par email.\",\n",
    "        \"Le chargement des images est très lent.\",\n",
    "        \"Les permissions d'accès sont incorrectes.\",\n",
    "        \"Le service client ne reçoit pas les messages.\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"critique\", \"moyen\", \"bas\", \"critique\", \"moyen\", \"bas\", \"critique\", \"bas\",\n",
    "        \"critique\", \"moyen\", \"moyen\", \"critique\", \"bas\", \"moyen\", \"critique\", \"moyen\",\n",
    "        \"critique\", \"bas\", \"critique\", \"critique\", \"moyen\", \"moyen\", \"moyen\", \"bas\",\n",
    "        \"moyen\", \"moyen\", \"moyen\", \"moyen\", \"moyen\", \"moyen\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Créer un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "file_path = \"notes_pannes.csv\"\n",
    "df.to_csv(file_path, index=False)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   note    30 non-null     object\n",
      " 1   label   30 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 608.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 note     label\n",
       " 0           Le serveur est en panne, tout est bloqué.  critique\n",
       " 1                  L'application est lente à charger.     moyen\n",
       " 2       Une fonctionnalité mineure ne fonctionne pas.       bas\n",
       " 3                   La base de données est corrompue.  critique\n",
       " 4   La page de connexion prend du temps à s'afficher.     moyen\n",
       " 5      Le bouton de téléchargement ne fonctionne pas.       bas\n",
       " 6            Le réseau est complètement hors service.  critique\n",
       " 7          Il y a un léger décalage dans l'affichage.       bas\n",
       " 8          Le système redémarre de manière aléatoire.  critique\n",
       " 9   Certains utilisateurs ne peuvent pas se connec...     moyen\n",
       " 10       Les emails ne sont pas envoyés correctement.     moyen\n",
       " 11  Le site web est inaccessible pour certains uti...  critique\n",
       " 12        Les notifications push ne fonctionnent pas.       bas\n",
       " 13      Les rapports ne sont pas générés comme prévu.     moyen\n",
       " 14            Le paiement en ligne ne fonctionne pas.  critique\n",
       " 15      Le temps de réponse du serveur est très lent.     moyen\n",
       " 16          Des erreurs 500 apparaissent fréquemment.  critique\n",
       " 17                L'interface utilisateur est boguée.       bas\n",
       " 18  Des fichiers sont manquants dans la base de do...  critique\n",
       " 19  Les utilisateurs sont déconnectés automatiquem...  critique\n",
       " 20        Le système de sauvegarde ne fonctionne pas.     moyen\n",
       " 21               Le processus de login est très lent.     moyen\n",
       " 22             Des erreurs de validation des données.     moyen\n",
       " 23  Les mises à jour ne sont pas appliquées correc...       bas\n",
       " 24  La recherche dans l'application ne fonctionne ...     moyen\n",
       " 25               Le tableau de bord ne s'affiche pas.     moyen\n",
       " 26  Les utilisateurs ne reçoivent pas leurs confir...     moyen\n",
       " 27            Le chargement des images est très lent.     moyen\n",
       " 28          Les permissions d'accès sont incorrectes.     moyen\n",
       " 29      Le service client ne reçoit pas les messages.     moyen,\n",
       " None,\n",
       "                                              note  label\n",
       " count                                          30     30\n",
       " unique                                         30      3\n",
       " top     Le serveur est en panne, tout est bloqué.  moyen\n",
       " freq                                            1     15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('notes_pannes.csv')\n",
    "df, df.info(), df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv(\"notes_pannes.csv\")\n",
    "\n",
    "# Mapper les labels en entiers\n",
    "label_mapping = {\"critique\": 0, \"moyen\": 1, \"bas\": 2}\n",
    "data['label'] = data['label'].map(label_mapping)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['note'].tolist(), data['label'].tolist(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  3%|▎         | 2/64 [00:00<00:28,  2.17it/s]\n",
      "  3%|▎         | 2/64 [00:00<00:28,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1187443733215332, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.851, 'eval_steps_per_second': 23.809, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 4/64 [00:01<00:28,  2.13it/s]\n",
      "  6%|▋         | 4/64 [00:01<00:28,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0964492559432983, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.852, 'eval_steps_per_second': 23.809, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6/64 [00:02<00:27,  2.07it/s]\n",
      "  9%|▉         | 6/64 [00:02<00:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0885125398635864, 'eval_runtime': 0.043, 'eval_samples_per_second': 139.533, 'eval_steps_per_second': 23.255, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 8/64 [00:03<00:26,  2.08it/s]\n",
      " 12%|█▎        | 8/64 [00:03<00:26,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0766834020614624, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.859, 'eval_steps_per_second': 23.81, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 10/64 [00:04<00:25,  2.09it/s]\n",
      " 16%|█▌        | 10/64 [00:04<00:25,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0737932920455933, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.859, 'eval_steps_per_second': 23.81, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 12/64 [00:05<00:25,  2.07it/s]\n",
      " 19%|█▉        | 12/64 [00:05<00:25,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0563627481460571, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.341, 'eval_steps_per_second': 24.39, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14/64 [00:06<00:24,  2.02it/s]\n",
      " 22%|██▏       | 14/64 [00:06<00:24,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0487877130508423, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.853, 'eval_steps_per_second': 23.809, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 16/64 [00:07<00:23,  2.06it/s]\n",
      " 25%|██▌       | 16/64 [00:07<00:23,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.048904538154602, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.341, 'eval_steps_per_second': 24.39, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18/64 [00:08<00:22,  2.06it/s]\n",
      " 28%|██▊       | 18/64 [00:08<00:22,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0415440797805786, 'eval_runtime': 0.047, 'eval_samples_per_second': 127.658, 'eval_steps_per_second': 21.276, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 20/64 [00:09<00:21,  2.04it/s]\n",
      " 31%|███▏      | 20/64 [00:09<00:21,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0393277406692505, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.856, 'eval_steps_per_second': 23.809, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 22/64 [00:10<00:20,  2.03it/s]\n",
      " 34%|███▍      | 22/64 [00:10<00:20,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0213762521743774, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.857, 'eval_steps_per_second': 23.809, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 24/64 [00:11<00:19,  2.02it/s]\n",
      " 38%|███▊      | 24/64 [00:12<00:19,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0028547048568726, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.856, 'eval_steps_per_second': 23.809, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 26/64 [00:13<00:19,  2.00it/s]\n",
      " 41%|████      | 26/64 [00:13<00:19,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9656118750572205, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.339, 'eval_steps_per_second': 24.39, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 28/64 [00:13<00:17,  2.04it/s]\n",
      " 44%|████▍     | 28/64 [00:14<00:17,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9272081255912781, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.341, 'eval_steps_per_second': 24.39, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 30/64 [00:14<00:16,  2.04it/s]\n",
      " 47%|████▋     | 30/64 [00:15<00:16,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9222326874732971, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.341, 'eval_steps_per_second': 24.39, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 32/64 [00:15<00:15,  2.06it/s]\n",
      " 50%|█████     | 32/64 [00:16<00:15,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9378530383110046, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.339, 'eval_steps_per_second': 24.39, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 34/64 [00:16<00:14,  2.06it/s]\n",
      " 53%|█████▎    | 34/64 [00:17<00:14,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9421439170837402, 'eval_runtime': 0.041, 'eval_samples_per_second': 146.343, 'eval_steps_per_second': 24.39, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 36/64 [00:17<00:13,  2.07it/s]\n",
      " 56%|█████▋    | 36/64 [00:18<00:13,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9385148882865906, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.856, 'eval_steps_per_second': 23.809, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 38/64 [00:18<00:12,  2.07it/s]\n",
      " 59%|█████▉    | 38/64 [00:19<00:12,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9231727719306946, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.852, 'eval_steps_per_second': 23.809, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 40/64 [00:19<00:11,  2.08it/s]\n",
      " 62%|██████▎   | 40/64 [00:19<00:11,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.916694700717926, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.854, 'eval_steps_per_second': 23.809, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 42/64 [00:20<00:10,  2.04it/s]\n",
      " 66%|██████▌   | 42/64 [00:21<00:10,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9073235392570496, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.857, 'eval_steps_per_second': 23.809, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 44/64 [00:22<00:09,  2.00it/s]\n",
      " 69%|██████▉   | 44/64 [00:22<00:09,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9066097140312195, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.855, 'eval_steps_per_second': 23.809, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 46/64 [00:23<00:08,  2.02it/s]\n",
      " 72%|███████▏  | 46/64 [00:23<00:08,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9069351553916931, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.856, 'eval_steps_per_second': 23.809, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 48/64 [00:24<00:07,  2.05it/s]\n",
      " 75%|███████▌  | 48/64 [00:24<00:07,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9286949038505554, 'eval_runtime': 0.043, 'eval_samples_per_second': 139.535, 'eval_steps_per_second': 23.256, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 50/64 [00:24<00:06,  2.07it/s]\n",
      " 78%|███████▊  | 50/64 [00:25<00:06,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9523162841796875, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.858, 'eval_steps_per_second': 23.81, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 52/64 [00:25<00:05,  2.07it/s]\n",
      " 81%|████████▏ | 52/64 [00:26<00:05,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.964904248714447, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.853, 'eval_steps_per_second': 23.809, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 54/64 [00:26<00:04,  2.09it/s]\n",
      " 84%|████████▍ | 54/64 [00:27<00:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9730550646781921, 'eval_runtime': 0.082, 'eval_samples_per_second': 73.171, 'eval_steps_per_second': 12.195, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 56/64 [00:28<00:03,  2.01it/s]\n",
      " 88%|████████▊ | 56/64 [00:28<00:03,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9777374267578125, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.856, 'eval_steps_per_second': 23.809, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 58/64 [00:29<00:02,  2.05it/s]\n",
      " 91%|█████████ | 58/64 [00:29<00:02,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9767656326293945, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.861, 'eval_steps_per_second': 23.81, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 60/64 [00:30<00:01,  2.04it/s]\n",
      " 94%|█████████▍| 60/64 [00:30<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9808658957481384, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.859, 'eval_steps_per_second': 23.81, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 62/64 [00:31<00:00,  2.06it/s]\n",
      " 97%|█████████▋| 62/64 [00:31<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9793005585670471, 'eval_runtime': 0.043, 'eval_samples_per_second': 139.534, 'eval_steps_per_second': 23.256, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:32<00:00,  2.03it/s]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9777347445487976, 'eval_runtime': 0.042, 'eval_samples_per_second': 142.855, 'eval_steps_per_second': 23.809, 'epoch': 32.0}\n",
      "{'train_runtime': 32.093, 'train_samples_per_second': 23.93, 'train_steps_per_second': 1.994, 'train_loss': 0.6566612720489502, 'epoch': 32.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model_classif\\\\tokenizer_config.json',\n",
       " './fine_tuned_model_classif\\\\special_tokens_map.json',\n",
       " './fine_tuned_model_classif\\\\vocab.txt',\n",
       " './fine_tuned_model_classif\\\\added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "# Charger le tokenizer et le modèle\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Préparer les datasets\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"input_ids\": train_encodings['input_ids'], \"attention_mask\": train_encodings['attention_mask'], \"labels\": train_labels})\n",
    "val_dataset = Dataset.from_dict({\"input_ids\": val_encodings['input_ids'], \"attention_mask\": val_encodings['attention_mask'], \"labels\": val_labels})\n",
    "\n",
    "# Configurer les arguments de l'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=32,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Créer un Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "trainer.train()\n",
    "\n",
    "# Sauvegarder le modèle fine-tuné\n",
    "model.save_pretrained(\"./fine_tuned_model_classif\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model_classif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 200.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9777347445487976, 'eval_runtime': 0.04, 'eval_samples_per_second': 150.005, 'eval_steps_per_second': 25.001, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La note est classifiée comme : bas\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "# Charger le modèle fine-tuné\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"./fine_tuned_model_classif\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./fine_tuned_model_classif\")\n",
    "\n",
    "# Fonction pour classifier une nouvelle note\n",
    "def classify_note(note):\n",
    "    inputs = tokenizer(note, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "    return predicted_class\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_note = \"il y a une baisse.\"\n",
    "predicted_class = classify_note(new_note)\n",
    "class_mapping = {0: \"critique\", 1: \"moyen\", 2: \"bas\"}\n",
    "print(f\"La note est classifiée comme : {class_mapping[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'toxic', 'score': 0.9288287162780762}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n",
    "#Ce modèle est une version affinée du modèle DistilBERT pour classer les commentaires toxiques.\n",
    "#https://huggingface.co/martin-ha/toxic-comment-model?text=I+like+you.+I+love+you\n",
    "\n",
    "model_path = \"martin-ha/toxic-comment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "result = pipeline('assole.') \n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
